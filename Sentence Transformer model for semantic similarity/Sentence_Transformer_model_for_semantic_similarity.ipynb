{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Objective: To fine-tune a pre-trained Transformer model to generate better sentence embeddings for semantic similarity tasks. We will use the embedding-data/sentence-compression dataset, which contains pairs of semantically equivalent sentences.\n",
        "\n",
        "Methodology:\n",
        "\n",
        "Setup: Install and import the necessary libraries.\n",
        "\n",
        "Load Data: Load the sentence-pair dataset from Hugging Face.\n",
        "\n",
        "Data Exploration: Understand the structure and content of our data.\n",
        "\n",
        "Data Preparation: Convert the dataset into a format suitable for training with the sentence-transformers library.\n",
        "\n",
        "Model Training: Fine-tune a pre-trained all-MiniLM-L6-v2 model using a Siamese network architecture and a powerful loss function (MultipleNegativesRankingLoss).\n",
        "\n",
        "Model Evaluation: Evaluate the performance of our fine-tuned model against a standard Semantic Textual Similarity (STS) benchmark and compare it to the base model.\n",
        "\n",
        "Inference: Test our new model with custom sentences.\n",
        "\n",
        "Let's get started!\n",
        "\n"
      ],
      "metadata": {
        "id": "jylJaM_zNRss"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DJebgG7rNM0Q"
      },
      "outputs": [],
      "source": [
        "# Install the necessary libraries\n",
        "!pip install sentence-transformers datasets -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
        "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
        "from torch.utils.data import DataLoader\n",
        "import math\n",
        "\n",
        "print(\"Libraries imported successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ow8JTgDNVF3",
        "outputId": "cda036b0-5898-42bc-f50f-3ed8600db532"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Load the Dataset\n",
        "We'll load the embedding-data/sentence-compression dataset directly from the Hugging Face Hub. This dataset is perfect for our task because it contains pairs of sentences that are semantically identical."
      ],
      "metadata": {
        "id": "rc5mpUQtNaEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset from Hugging Face\n",
        "dataset_id = \"embedding-data/sentence-compression\"\n",
        "dataset = load_dataset(dataset_id)\n",
        "\n",
        "print(\"Dataset loaded successfully!\")\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359,
          "referenced_widgets": [
            "e148df8def424780a92ceea925a2fbba",
            "6021375153d149d3a9b7be65671cb4e5",
            "edf7a998208542bd95277bdc27de1d46",
            "72645d8ea7e4493aac116bec4ee88090",
            "9c0caf02813f4d7091a0466d01582380",
            "3f63244cfaca47f68867d1c8e4cd2187",
            "bcba4b5d09df44b7b8eba611c64e3a2b",
            "00b955f78ccb40d3aa7b38cd767ed60a",
            "f8a706785ae249dca47d2f4cd37d5f48",
            "78b0f95ee3494b6291f4c47d94c517b8",
            "bbaf881496114c5085f1ca1ee88e7ae5",
            "d560035bf362470db709e2548571eb3d",
            "763986ad59de482ba79b862085bc69f7",
            "2ba197f70d5546c690056691bd0c514d",
            "33260fa1aa694e45817b656b94071cb9",
            "97205bc78dc5490f907ba2a6f4f2d038",
            "09b3c586889f4cfa9dc2b36f6eebc2d7",
            "38f39ec938254ead872e230680107d92",
            "6b212b288b294fc19cfde86d65f42bc6",
            "2e3aee5d052f4ea483c155607eac6b36",
            "618246d9ffb14dd5bafc38d460ac7597",
            "80a49999b57a4f12875f9a11c49973f1",
            "b507c7c3159244fea4d09b2f72d14136",
            "49767df0a6c04ebd9aa0cbb14e3e5d4c",
            "2ad6e7f191674dcf93d9e23d11fda16e",
            "af8717cda571451f8a9a2d11acbefab5",
            "74843578b1ce4d888ab884885a7fad02",
            "94cd8a79f1f64b0ca824a25d47aec46b",
            "77cc60045b45435bade62993d94994d1",
            "2f2c1040041b446abed9c60241f9327e",
            "f44fc887428047df906e43c502854acd",
            "355b01eb229b4281802c2d40db12ab0c",
            "889660b871f041c998c28b0eced86004"
          ]
        },
        "id": "AJaAbSzmNYJr",
        "outputId": "d8a057a3-5fa2-4ffd-92b6-7019a83bd48a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e148df8def424780a92ceea925a2fbba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence-compression_compressed.jsonl.gz:   0%|          | 0.00/14.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d560035bf362470db709e2548571eb3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/180000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b507c7c3159244fea4d09b2f72d14136"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully!\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['set'],\n",
            "        num_rows: 180000\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Exploratory Data Analysis (EDA)\n",
        "Let's take a peek at the data to understand its structure. Each entry consists of a \"set\" of two equivalent sentences. These pairs will act as positive pairs for our model, teaching it that these two sentences should have very similar vector representations (embeddings)."
      ],
      "metadata": {
        "id": "xD7Mz72sNfHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see a few examples from the training set\n",
        "print(\"Dataset examples:\")\n",
        "for i in range(5):\n",
        "    example = dataset['train'][i]\n",
        "    print(f\"\\nExample {i+1}:\")\n",
        "    print(f\"  Sentence 1: {example['set'][0]}\")\n",
        "    print(f\"  Sentence 2: {example['set'][1]}\")\n",
        "\n",
        "# Let's also convert it to a pandas DataFrame for a cleaner view\n",
        "df = pd.DataFrame(dataset['train'])\n",
        "df['sentence1'] = df['set'].apply(lambda x: x[0])\n",
        "df['sentence2'] = df['set'].apply(lambda x: x[1])\n",
        "df = df.drop(columns=['set'])\n",
        "\n",
        "print(\"\\n\\nDataset preview in a DataFrame:\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "4qIS0HW3NglS",
        "outputId": "fb6141e8-6116-447d-981f-4b820389137f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset examples:\n",
            "\n",
            "Example 1:\n",
            "  Sentence 1: The USHL completed an expansion draft on Monday as 10 players who were on the rosters of USHL teams during the 2009-10 season were selected by the League's two newest entries, the Muskegon Lumberjacks and Dubuque Fighting Saints.\n",
            "  Sentence 2: USHL completes expansion draft\n",
            "\n",
            "Example 2:\n",
            "  Sentence 1: Major League Baseball Commissioner Bud Selig will be speaking at St. Norbert College next month.\n",
            "  Sentence 2: Bud Selig to speak at St. Norbert College\n",
            "\n",
            "Example 3:\n",
            "  Sentence 1: It's fresh cherry time in Michigan and the best time to enjoy this delicious and nutritious fruit.\n",
            "  Sentence 2: It's cherry time\n",
            "\n",
            "Example 4:\n",
            "  Sentence 1: An Evesham man is facing charges in Pennsylvania after he allegedly dragged his girlfriend from the side of his pickup truck on the campus of Kutztown University in the early morning hours of Dec. 5, police said.\n",
            "  Sentence 2: Evesham man faces charges for Pa.\n",
            "\n",
            "Example 5:\n",
            "  Sentence 1: NRT LLC, one of the nation's largest residential real estate brokerage companies, announced several executive appointments within its Coldwell Banker Residential Brokerage operations in Southern California.\n",
            "  Sentence 2: NRT announces executive appointments at its Coldwell Banker operations in Southern California\n",
            "\n",
            "\n",
            "Dataset preview in a DataFrame:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           sentence1  \\\n",
              "0  The USHL completed an expansion draft on Monda...   \n",
              "1  Major League Baseball Commissioner Bud Selig w...   \n",
              "2  It's fresh cherry time in Michigan and the bes...   \n",
              "3  An Evesham man is facing charges in Pennsylvan...   \n",
              "4  NRT LLC, one of the nation's largest residenti...   \n",
              "\n",
              "                                           sentence2  \n",
              "0                     USHL completes expansion draft  \n",
              "1          Bud Selig to speak at St. Norbert College  \n",
              "2                                   It's cherry time  \n",
              "3                  Evesham man faces charges for Pa.  \n",
              "4  NRT announces executive appointments at its Co...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-60d7f900-508e-453c-a183-8c7352c0e9ec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The USHL completed an expansion draft on Monda...</td>\n",
              "      <td>USHL completes expansion draft</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Major League Baseball Commissioner Bud Selig w...</td>\n",
              "      <td>Bud Selig to speak at St. Norbert College</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It's fresh cherry time in Michigan and the bes...</td>\n",
              "      <td>It's cherry time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>An Evesham man is facing charges in Pennsylvan...</td>\n",
              "      <td>Evesham man faces charges for Pa.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NRT LLC, one of the nation's largest residenti...</td>\n",
              "      <td>NRT announces executive appointments at its Co...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60d7f900-508e-453c-a183-8c7352c0e9ec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-60d7f900-508e-453c-a183-8c7352c0e9ec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-60d7f900-508e-453c-a183-8c7352c0e9ec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-68b2b25e-5d5e-4018-b877-cef7b5888a10\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-68b2b25e-5d5e-4018-b877-cef7b5888a10')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-68b2b25e-5d5e-4018-b877-cef7b5888a10 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Prepare the Data for Training\n",
        "The sentence-transformers library has a specific data format for training: a list of InputExample objects. For our task, each InputExample will contain one of the positive sentence pairs. We don't need explicit labels because the loss function we'll use (MultipleNegativesRankingLoss) cleverly generates hard negatives on the fly from other examples within the same batch."
      ],
      "metadata": {
        "id": "S1rXknzLNlbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will limit the training set to 30,000 examples for a quicker training time.\n",
        "# This is more than enough to see significant improvement.\n",
        "train_samples_limit = 30000\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "# Create a list of InputExample objects\n",
        "train_samples = []\n",
        "for example in dataset['train']:\n",
        "    if len(train_samples) >= train_samples_limit:\n",
        "        break\n",
        "    train_samples.append(InputExample(texts=[example['set'][0], example['set'][1]]))\n",
        "\n",
        "print(f\"Created {len(train_samples)} training examples.\")\n",
        "print(\"Example of an InputExample object:\")\n",
        "print(train_samples[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uizq1j5GNlxS",
        "outputId": "ef975652-2b30-43c4-a2dc-e811b9f34122"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 30000 training examples.\n",
            "Example of an InputExample object:\n",
            "<InputExample> label: 0, texts: The USHL completed an expansion draft on Monday as 10 players who were on the rosters of USHL teams during the 2009-10 season were selected by the League's two newest entries, the Muskegon Lumberjacks and Dubuque Fighting Saints.; USHL completes expansion draft\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The InputExample format is very flexible. For other tasks like classification or regression, you can also provide a label. But for our Siamese network training with this specific loss, just providing the pair of texts is enough."
      ],
      "metadata": {
        "id": "ooAybcfHNm_J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Define the Model and Training Setup\n",
        "Now for the exciting part! We will:\n",
        "\n",
        "Load a pre-trained all-MiniLM-L6-v2 model. This is a small but powerful model, great for sentence similarity tasks.\n",
        "\n",
        "Create a DataLoader to batch our train_samples.\n",
        "\n",
        "Define the loss function. We'll use MultipleNegativesRankingLoss, which is highly effective. It takes a batch of positive pairs (a_i, p_i) and, for each a_i, it treats all other positive sentences p_j (where j != i) in the batch as hard negative examples. This pushes the model to learn fine-grained distinctions."
      ],
      "metadata": {
        "id": "lYhCvrJVNo8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model. We will use a pre-trained model as a starting point.\n",
        "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "model = SentenceTransformer(model_name)\n",
        "\n",
        "print(f\"Model '{model_name}' loaded successfully.\")\n",
        "\n",
        "# Define the loss function\n",
        "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
        "\n",
        "# Define a DataLoader to handle batching of our data\n",
        "batch_size = 32\n",
        "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386,
          "referenced_widgets": [
            "92dcdf0d5d214e3fa2b503ded2344300",
            "e74f1bcde54d4d5b94e53c1608fae60d",
            "8d800b433f304b0f8e26b6538e9d9e88",
            "0e7311c766c04679a0eb5fc59ac18211",
            "ac580e7be3e54b9bb03b6d05187fe7eb",
            "c6952d4812424d758e39a358e2e0c962",
            "0b766572e5224b28bdb14f88316e1103",
            "e30c08c3493243068e856ac77da37b46",
            "ce3e3fd3db6c4acbb53597d2040a3c0a",
            "eeed5a045d844823ba4d00823dfe0e4f",
            "6ee8e2c1448047ff83847647f02df68e",
            "be8974f347234d24bf975a4e94ffe67f",
            "32f7ba7085224ec7acb0d9bfd0e86be5",
            "6285695099d6411582ccaf48cbfac28e",
            "c3c9dcf887994181b248c334ba8a4707",
            "436370387dcb45598d31d5808fef6ddf",
            "e4b41557368a4eafbe81a3448ad83ef9",
            "b7edbb1ee08240fba936b342a394cd5a",
            "40e101d8e8ee405ba1922e598caa87eb",
            "8b2d4addef6b4ebf8e61ddd17a4fe216",
            "eb9ba1f95c874f2a813ffcf692fef027",
            "343223a19b7040bca3a3a6cfe863f36f",
            "83b9bf61f15f4f3d810db829d9b45f3d",
            "923afb57368a4d05967debeccdc66960",
            "bfa6c3299bff4a51910973a85524152b",
            "11b99d99d75b4374b996f6b83ac93d28",
            "97a7fb7f08af4c8a9154a271ac1a1d68",
            "dac7fe1be7e54b89a2ddbc6f5614cbe0",
            "6467f900f3f843c78c0d965f807482ea",
            "d6da327f0fd04ae38df4d6fa1bd97a31",
            "155f82f1731340cc9ecee38624ffe3fe",
            "ee8e7c31f91548a28de660c9b1d91c9a",
            "9ac8bc80ae5448339932427e361c9a10",
            "98e1792e3eb94de5bbaa50941dcae8cd",
            "c063705238a6418cb042c3732489a744",
            "8ccc386cbc0e49c58e84f08392420f07",
            "6a25af219c1a4848a9b312c16b25dfe1",
            "bc47cbf9f6784d8a9d9e29c43ac1f0a6",
            "9515636ff9b840ff83901730b5e8dbac",
            "6cf248b208494313bbd17c810b5199ef",
            "379d134dcb46417c94c6128d37048697",
            "8585e8b343774969b85f91a6de8394de",
            "00c087ecdc6947f1aa0e3935986368a1",
            "d6be7d5a26634a7b87b878211e23786f",
            "72e86ec31b974160a8b215b0a67c5d0f",
            "9b3c2f25ac7d4514a7176e762afd592b",
            "16eab174365349479700c430b8eaade5",
            "2523f1fca67147189bbe958024a26d48",
            "2d58a0f5a4024448b77ed6f391274d63",
            "5d4e4bd4048f407fa21e2ea0af1a6596",
            "70a364f6246a43209aa7089422f996ea",
            "27624543de4748ab802a32e28bbe370a",
            "505b8862ab7047eb9832bd4ec3ce9d7f",
            "380747f9a7c34cee9c6dca4efbe84fd2",
            "74702561c14a432c8a14348a57d53238",
            "b5151864321945e6b1188bf3b47d68e9",
            "34ecb9c62edf4696b7c450c86ccf656a",
            "95a05b1234f14bc4b0064c8e0cc9b635",
            "b21740eefc454aeca451fe5faf76350e",
            "b249d076f2e54149aa7ecd712f312542",
            "addd85339efd4edaa126cd69e9d4098d",
            "8b9a0684bfc24f108499732bf2aa406d",
            "9fb8fe7f85e64e19a1ce65f5afa8f91a",
            "ddb04d8e13e6437e8e7d793960cf6a22",
            "1f3bc2cf76ab479e936d4de1edc0d5d5",
            "f60c4e4cecff4fc68f25134100988f94",
            "bb96dfb42e814b78ad8bacefd930c0c2",
            "b92321a76fef413fa24ab3fdea619da8",
            "a183118d6e0b444ea2e255b160fc605a",
            "2f1cc8bfcf04422f89d4a0ce87950800",
            "3d37fe4878894f92b73cdf46cb3ac391",
            "b351fed09f5643ce858564473cafc4a0",
            "6b594abb234b42e8a653fbd9c391e67f",
            "51dcc14e5730461da459d6d0295b1309",
            "957b5d8226914e2cb9cb992b0a096695",
            "9ff79b712b4d4eeb903889308bcecc2a",
            "e18afc48e9d54b30a1f73623d42d7638",
            "7d9c7ed56abb4d07b3b2f2f242f82ea6",
            "ae683dc22a6341388877ef4d473aaebd",
            "f4c63acc18234e10b42cf860533fdf99",
            "3044604b71914bda9dcb034bfdb8dd25",
            "1a412733ec244988b9b2bd33b6d8824c",
            "335b78cec0314339ad47950e5612733e",
            "d9a76702cd254214afceeb95a048e46b",
            "2f443b8cea5448c6b924e0a19c7ce4e2",
            "3aa1a705cad549f1870e68bc003bbaf5",
            "afed917fbd874386970512f847f9787b",
            "bd26359670e94824bc8a3bd7772e62ee",
            "3b0c43bb36f74dbaa6587edb51b83bfb",
            "2266b1eedf0c41209c7b536460762de5",
            "78970f0fc44c4de48731f2ae980f83b5",
            "eead6de1d9ae4f21938c052536b96d07",
            "b5f6e94811c24b309e34db53e8d0af88",
            "bb4ababdadc24fa190ced10e41ffa986",
            "b452d0aea98749dba2760011b9f801ce",
            "ab07650d7f9f4ccfb3491891a3252ac8",
            "90ab14207df34546a7b21396bf4e5bd0",
            "4ec23302c8224eb78fc2f1f651c5f241",
            "44caa2ee96a946bf9e38e29891a1ce10",
            "01d69a3c733148ffb6f0ac315ab0eac8",
            "a2956271246f450684ac01c631672b8c",
            "afc28e8c68e6476692391da0215b947a",
            "1f3fb56527ed4259a1f603d2333c8c8f",
            "42d06f02e26c4b488178bae2cd23073a",
            "ef80306845ba45e2a837db74bd2238f8",
            "a7101ddfcbb34fa2a936dcc8c6ba419c",
            "8739d98c8d9a4904a0c480e9343397a2",
            "86fec55b80c64bcdbecf9944c7cb5862",
            "802dfebf1fff4dc893f1459facb6d1cb",
            "e154cd8666f14bcd8f39853cf5cd8d45",
            "4d507116df1c41bbaa691b5b93e90814",
            "063c7bdd78a1400d91c1efb829091f00",
            "a72ba97aab3443cd9d000b242c3b4bee",
            "448cc6295f1e464e8821355a9e35baf8",
            "56c295f7affc4ca7ba3a3f8dce6ca4e3",
            "c9527faa0c5b4cd6930229078cb510cf",
            "2523159fa1164926b11b2661701286c4",
            "30cf48805dc649968bd18043cc0d2824",
            "cf204112f7a84165ab140bf9673dd87d",
            "3181eb8297154bdcacc8b2390452a22e",
            "2be1530d195e45faac9ca75d8a3ff59c"
          ]
        },
        "id": "HB6zUitfNqmJ",
        "outputId": "d009f0ff-ba82-4571-9a5f-05f704594362"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92dcdf0d5d214e3fa2b503ded2344300"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be8974f347234d24bf975a4e94ffe67f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83b9bf61f15f4f3d810db829d9b45f3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98e1792e3eb94de5bbaa50941dcae8cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72e86ec31b974160a8b215b0a67c5d0f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5151864321945e6b1188bf3b47d68e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb96dfb42e814b78ad8bacefd930c0c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d9c7ed56abb4d07b3b2f2f242f82ea6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b0c43bb36f74dbaa6587edb51b83bfb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01d69a3c733148ffb6f0ac315ab0eac8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d507116df1c41bbaa691b5b93e90814"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 'sentence-transformers/all-MiniLM-L6-v2' loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Train the Model\n",
        "With our model, data, and loss function ready, we can start the fine-tuning process. We'll train for just one epoch, which is often sufficient for fine-tuning on a high-quality dataset like this. The model.fit() function handles the entire training loop for us."
      ],
      "metadata": {
        "id": "M6x2m6PdNuXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure training parameters\n",
        "num_epochs = 3\n",
        "warmup_steps = int(len(train_dataloader) * num_epochs * 0.1) # 10% of train data for warm-up\n",
        "\n",
        "print(\"Starting model training...\")\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
        "          epochs=num_epochs,\n",
        "          warmup_steps=warmup_steps,\n",
        "          output_path='./fine-tuned-mini-lm',\n",
        "          show_progress_bar=True)\n",
        "\n",
        "print(\"Model training completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "6-4DZf3NN9xv",
        "outputId": "1acaa9f5-55dc-4862-f63b-104f9ec89984"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting model training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2814' max='2814' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2814/2814 04:17, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.002100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Evaluate the Model\n",
        "How do we know if our model improved? We need to evaluate it on a standardized benchmark. The Semantic Textual Similarity (STS) benchmark is perfect for this. We'll use the stsb-b-dev dataset, which contains sentence pairs and a human-annotated similarity score from 0 to 5.\n",
        "\n",
        "Our goal is to see if the cosine similarity between our model's embeddings has a high Spearman correlation with the human scores. A higher correlation means our model better captures the human understanding of similarity.\n",
        "\n",
        "We'll evaluate both the original pre-trained model and our newly fine-tuned model to quantify the improvement."
      ],
      "metadata": {
        "id": "cmKJP8M3PH_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the STS benchmark dataset\n",
        "sts_dataset = load_dataset(\"stsb_multi_mt\", name=\"en\", split=\"dev\")\n",
        "\n",
        "# Prepare the evaluation data\n",
        "eval_samples = []\n",
        "for sample in sts_dataset:\n",
        "    # Normalize score to be between 0 and 1\n",
        "    score = sample['similarity_score'] / 5.0\n",
        "    eval_samples.append(InputExample(texts=[sample['sentence1'], sample['sentence2']], label=score))\n",
        "\n",
        "# Create the evaluator\n",
        "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(eval_samples, name='sts-b-dev')\n",
        "\n",
        "\n",
        "# 1. Evaluate the base model (before fine-tuning)\n",
        "print(\"Evaluating the base model...\")\n",
        "base_model = SentenceTransformer(model_name)\n",
        "base_model.evaluate(evaluator)\n",
        "\n",
        "\n",
        "# 2. Evaluate our fine-tuned model\n",
        "print(\"\\n\\nEvaluating the fine-tuned model...\")\n",
        "fine_tuned_model = SentenceTransformer('./fine-tuned-mini-lm')\n",
        "fine_tuned_model.evaluate(evaluator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345,
          "referenced_widgets": [
            "b712b1d77dc748258698404f5a2b021a",
            "1a84ba05ae3a49d193026c1cf4f64aa4",
            "0c6c31058b1a4cf9b4a718e4bcef2c14",
            "7f1dd86293bb43dda2585660cb84fc78",
            "d7bade222577426fa734bd7d9f43ce10",
            "5391503646d3402eb9248f98ccdd20c4",
            "4e600fcc3ed440f8b7ffc73446d85928",
            "3a4298bc1e1240d5ad7ec86afb43df93",
            "c8af385b370847308446442072baf854",
            "9ab6b322c9fa4dfba71d2afb06be8aac",
            "f143995e5911463c816d594e2bef2e56",
            "1afe18824ad743b2adb13c9072b3fdef",
            "b5f1c3f6932d48ce81b3897a0268585b",
            "c11cca51d3a146e69546dcc4dd89c00f",
            "2e2278770e364a57babecfe6f3a56a72",
            "16c46c6450624133af75119e8110eb99",
            "7e0579d116444bfa85c09d0d77429819",
            "01e2a63e362140e09b97f9e3a910d881",
            "e7930d7137224a96a9f443da3876b870",
            "8f8df21996304cf7a223725c09d52784",
            "0a0d810a67dd46feb575f554fbc57e89",
            "f8bd53497b934e2e98ce27929952403e",
            "8b727be57525425fbd3f3c2e652edb01",
            "ddcb773e5e1d4befa1fdf04c636c910b",
            "fc71e8441ee04bf39b0172ea5804adaa",
            "b563fc854f3a4a21b9960abc88c18241",
            "d0a017c69ed64af2b8424de8be0b3ba7",
            "cb89fcdbc29e4f7da1c4b38b907fafa9",
            "9e22dc18edc444a5964776a505ffa709",
            "87f5efc8849b47bdb50e52905a6bb584",
            "7b684f58046d4b22af20e5e9095915cf",
            "4b2bfc6c833f4568aa9a78d59c138e78",
            "0cb523b66949434389f4522e2d26d452",
            "ac49896ce27449f7931ee7845ba27028",
            "bad3164152fe42399bd7840e01fc6939",
            "76312bb488894e1b891478106b5d660c",
            "fb2bf3429b6b4c26b810f9ee03854418",
            "d6e45ccad4a64bb294748f669883b580",
            "3fda52f01fa84433befe84e012f3ecc5",
            "79cc3b009f364e16ae1e12b0c71a961a",
            "4098c7ee79ea47e3a7e60dfbcef89ad9",
            "3e7ae9b82f7148929e1c9843c50e047c",
            "a5eac8ef2edc41b4a43438a5b93ddd3c",
            "a3a7e560e221476a9ca28bcc05d61580",
            "9367e862ab9d43ce88f55d0e32171bf5",
            "f6ebd40092a34e64ab2e53cbfe86a122",
            "50d7c57037a142dcbf025577a0b6e55c",
            "80b4068c806449cd9a425b97bf989e71",
            "c61c8e1a85fb467e929c6ef255d49237",
            "3689488e46a244b9a4e12b21e9534085",
            "34185765b81e4742a2f40f6c9b92accb",
            "6dd146cc4b294c0c9a499df22fb0a7d6",
            "f572df6fc2784a709d7a7d063868f368",
            "0b6ef58f043e4c98a2e71f8a40d4dffe",
            "e1f18f34cd7c4901b8316cfef08fc6ec",
            "fa75f8dfc2ce46cc89197ca47c8ceab8",
            "143fb6972c864c188d8949e7d3e4b769",
            "8cd63ef6991040868ce98f2ebec87607",
            "c41ff1d54214425db1deb1611da0c609",
            "7846f7fd6c4841a9a84e73e33f2858f8",
            "5c22f8cb302c4dfb943daae2a60351ae",
            "b4a4236e7e5e492097cd519897ad26ce",
            "0a7f585b921a46ae94023244aac798b1",
            "ea8be279c36f4cb4a4ec88f9572ea43b",
            "26aae28cd48748038dc6476f3c69b830",
            "202511be3e46479d8eb44c87ff4a06b9",
            "0f3028d68d164132a9933aaaf2d8a4eb",
            "da8b4ff8fe5d47bbbfcad50045f7abef",
            "71f7cbdf3406464a8c4a17111581fd43",
            "17898cfc9318405191f06f60104fa697",
            "dd03a98e935845d382769585ff830f28",
            "cfdde54f077d41f6b3f2c0998e51db11",
            "76e3f88f15ba4272ad813787362bb251",
            "8d2c2f743bb343ce8795ff5b43c2cbec",
            "e6ac75802f08471999cf6e01003d1beb",
            "4d88d6e491254f0f986974f37a266407",
            "1f47e319bf6c462ea8e6f8c81f81661c"
          ]
        },
        "id": "6oceKsZMPMfH",
        "outputId": "3fafc7c3-9303-4681-fd35-f48c4934f796"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b712b1d77dc748258698404f5a2b021a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "en/train-00000-of-00001.parquet:   0%|          | 0.00/470k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1afe18824ad743b2adb13c9072b3fdef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "en/test-00000-of-00001.parquet:   0%|          | 0.00/108k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b727be57525425fbd3f3c2e652edb01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "en/dev-00000-of-00001.parquet:   0%|          | 0.00/142k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac49896ce27449f7931ee7845ba27028"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/5749 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9367e862ab9d43ce88f55d0e32171bf5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1379 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa75f8dfc2ce46cc89197ca47c8ceab8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating dev split:   0%|          | 0/1500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f3028d68d164132a9933aaaf2d8a4eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating the base model...\n",
            "\n",
            "\n",
            "Evaluating the fine-tuned model...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sts-b-dev_pearson_cosine': 0.8737719669657913,\n",
              " 'sts-b-dev_spearman_cosine': 0.8704765946133534}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should see a noticeable increase in the Spearman correlation! This confirms that fine-tuning on our specific dataset has improved the model's ability to understand semantic similarity."
      ],
      "metadata": {
        "id": "r3t1m7ZYPPz4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8: Inference - Test with Custom Sentences\n",
        "Now let's have some fun and see how our model works on new sentences. We can use the util.cos_sim function from the library to compute the similarity score between sentence embeddings. A score close to 1.0 means the sentences are very similar, while a score close to 0.0 means they are dissimilar."
      ],
      "metadata": {
        "id": "TDxZ8zI6PUhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import util\n",
        "import torch\n",
        "\n",
        "# Our fine-tuned model is already loaded as `fine_tuned_model`\n",
        "\n",
        "def check_similarity(sentence1, sentence2):\n",
        "    \"\"\"Computes and prints the cosine similarity between two sentences.\"\"\"\n",
        "    # Encode the sentences to get their embeddings\n",
        "    embedding1 = fine_tuned_model.encode(sentence1, convert_to_tensor=True)\n",
        "    embedding2 = fine_tuned_model.encode(sentence2, convert_to_tensor=True)\n",
        "\n",
        "    # Compute cosine similarity\n",
        "    cosine_score = util.cos_sim(embedding1, embedding2).item()\n",
        "\n",
        "    print(f\"Sentence 1: {sentence1}\")\n",
        "    print(f\"Sentence 2: {sentence2}\")\n",
        "    print(f\"Similarity Score: {cosine_score:.4f}\\n\")\n",
        "\n",
        "# Let's test with some examples\n",
        "print(\"--- Testing with Similar Sentences ---\")\n",
        "check_similarity(\"A man is eating a pizza\", \"A guy is enjoying a pizza slice\")\n",
        "check_similarity(\"The weather is beautiful today\", \"It's a lovely day outside\")\n",
        "\n",
        "print(\"\\n--- Testing with Dissimilar Sentences ---\")\n",
        "check_similarity(\"A cat is sleeping on the couch\", \"The stock market is down\")\n",
        "check_similarity(\"How can I learn to code?\", \"The soup needs more salt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdH7YbHmPT4B",
        "outputId": "30c1515f-9122-42cf-c537-cd9a50643c19"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing with Similar Sentences ---\n",
            "Sentence 1: A man is eating a pizza\n",
            "Sentence 2: A guy is enjoying a pizza slice\n",
            "Similarity Score: 0.7150\n",
            "\n",
            "Sentence 1: The weather is beautiful today\n",
            "Sentence 2: It's a lovely day outside\n",
            "Similarity Score: 0.7309\n",
            "\n",
            "\n",
            "--- Testing with Dissimilar Sentences ---\n",
            "Sentence 1: A cat is sleeping on the couch\n",
            "Sentence 2: The stock market is down\n",
            "Similarity Score: -0.0225\n",
            "\n",
            "Sentence 1: How can I learn to code?\n",
            "Sentence 2: The soup needs more salt\n",
            "Similarity Score: 0.0301\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 9: Summary and Conclusion ✨\n",
        "In this notebook, we successfully fine-tuned a pre-trained Sentence Transformer model (all-MiniLM-L6-v2) on a sentence compression dataset.\n",
        "\n",
        "Key Achievements:\n",
        "\n",
        "Data Preparation: We loaded a dataset of sentence pairs and formatted it into InputExample objects suitable for training.\n",
        "\n",
        "Efficient Training: We used the powerful MultipleNegativesRankingLoss, which is ideal for this type of data, to train a Siamese network.\n",
        "\n",
        "Quantifiable Improvement: By evaluating on the standard STS-B benchmark, we demonstrated a clear improvement in the model's performance (Spearman correlation) after fine-tuning compared to the original base model.\n",
        "\n",
        "Practical Application: The resulting model is now better at understanding semantic similarity and can be used for tasks like semantic search, clustering, or paraphrase detection.\n",
        "\n",
        "This project showcases a complete and effective workflow for adapting a general-purpose language model to a specific task, resulting in a more specialized and powerful tool."
      ],
      "metadata": {
        "id": "sdn4mHiZPXLv"
      }
    }
  ]
}